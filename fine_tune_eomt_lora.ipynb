{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Fine-tune EoMT with LoRA on Google Colab\n",
                "\n",
                "This notebook provides a step-by-step guide to fine-tune the EoMT (End-of-Model-Training) model using Logit Normalization and LoRA (Low-Rank Adaptation). \n",
                "\n",
                "## 1. Environment Setup\n",
                "First, we check the GPU status and install necessary dependencies."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Mount Google Drive\n",
                "Run the cell below to mount your Google Drive. You will be asked to authorize access.\n",
                "After mounting, your Drive files will be available at `/content/drive/MyDrive`.\n",
                "\n",
                "**IMPORTANT:** Update `PROJECT_PATH` below to the folder in your Drive where you uploaded this project."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "import os\n",
                "\n",
                "# 1. Mount Drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# 2. Define your project path (Change this to your actual folder name)\n",
                "PROJECT_PATH = '/content/drive/MyDrive/MaskArchitectureAnomaly_CourseProject'\n",
                "\n",
                "# 3. Change directory\n",
                "try:\n",
                "    os.chdir(PROJECT_PATH)\n",
                "    print(f\"Successfully changed directory to: {os.getcwd()}\")\n",
                "except FileNotFoundError:\n",
                "    print(f\"Error: The path '{PROJECT_PATH}' does not exist. Please check the path variable.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Install Dependencies\n",
                "We need to install the libraries specified in `eomt/requirements.txt`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -r eomt/requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Python Path Setup\n",
                "To ensure all modules (like `training`, `eomt`, `datasets`) are importable, we add the necessary paths to `sys.path`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# Add current directory (project root)\n",
                "if os.getcwd() not in sys.path:\n",
                "    sys.path.append(os.getcwd())\n",
                "\n",
                "# Add 'eomt' subdirectory as it contains 'training' and 'datasets' packages\n",
                "eomt_path = os.path.join(os.getcwd(), 'eomt')\n",
                "if eomt_path not in sys.path:\n",
                "    sys.path.append(eomt_path)\n",
                "\n",
                "print(\"Python path updated.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run Training with LoRA\n",
                "Verified training command using `train_net_lora.py` with PyTorch Lightning CLI.\n",
                "\n",
                "### Key Arguments:\n",
                "- `--lora_rank`: Rank of the LoRA adapters (default: 32).\n",
                "- `--logit_norm_temperature`: Temperature for logit normalization (default: 0.04).\n",
                "- `--head_only`: If set, only trains the head (faster, less memory).\n",
                "- `--trainer.default_root_dir`: Directory to save checkpoints and logs.\n",
                "- `--config`: Path to the YAML config file.\n",
                "\n",
                "**Note:** Ensure your dataset path in the config file or command argument points to the correct location in Colab."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example Training Command\n",
                "# Adjust paths (pretrained_path, data path) as necessary for your Colab environment\n",
                "\n",
                "!python eomt/train_net_lora.py fit \\\n",
                "    --config eomt/configs/dinov2/cityscapes/semantic/eomt_base_640.yaml \\\n",
                "    --compile_disabled \\\n",
                "    --model.ckpt_path \"trained_eomt/eomt_cityscapes.bin\" \\\n",
                "    --data.init_args.img_size=\"[1024, 1024]\" \\\n",
                "    --lora_rank 32 \\\n",
                "    --lora_alpha 64 \\\n",
                "    --logit_norm_temperature 0.04 \\\n",
                "    --trainer.default_root_dir \"training_output\" \\\n",
                "    --trainer.max_epochs 10 \\\n",
                "    --trainer.check_val_every_n_epoch 10 \\\n",
                "    --data.init_args.batch_size 4 \\\n",
                "    --trainer.accumulate_grad_batches 4 \\\n",
                "    --lora_targets=\"[\"class_head\", \"mask_head\"]\" \\\n",
                "    --trainer.logger.init_args.name \"no-lora-t=0.04-no_load\" \\\n",
                "    --data.init_args.path \"eomt/cityscapes\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Output Location\n",
                "Checkpoints will be saved in `training_output/lightning_logs/version_X/checkpoints/`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Troubleshooting\n",
                "- **ModuleNotFoundError**: Make sure you ran the `sys.path` cell and are in the correct root directory.\n",
                "- **CUDA OOM**: Reduce `batch_size` or use `--head_only`.\n",
                "- **Data Not Found**: verify `--data.init_args.path` is correct."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python eomt/finetune.py fit \\\n",
                "    --config eomt/configs/dinov2/cityscapes/semantic/eomt_base_640.yaml \\\n",
                "    --compile_disabled \\\n",
                "    --model.ckpt_path \"trained_eomt/eomt_cityscapes.bin\" \\\n",
                "    --trainer.max_epochs=10 \\\n",
                "    --trainer.check_val_every_n_epoch 10 \\\n",
                "    --data.init_args.img_size=\"[1024, 1024]\" \\\n",
                "    --data.init_args.batch_size=4 \\\n",
                "    --trainer.accumulate_grad_batches 4 \\\n",
                "    --data.init_args.path=\"cityscapes\" \\\n",
                "    --logit_norm_temperature 1.2 \\\n",
                "    --targets=\"[\"class_head\", \"mask_head\"]\" \\\n",
                "    --trainer.logger.init_args.name \"no-lora-t=0.04-no_load\" \\\n",
                "    --data.init_args.path \"eomt/cityscapes\"\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
