{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# EoMT Architecture Visualization\n",
                "\n",
                "This notebook visualizes the architecture of the EoMT (End-to-End Mask Transformer?) model used in the project. It instantiates the model with default configuration parameters and performs a dummy forward pass to show input/output shapes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "32573db3",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# Add the current directory to sys.path to ensure modules can be imported\n",
                "sys.path.append(os.getcwd())\n",
                "os.environ.setdefault(\"KMP_DUPLICATE_LIB_OK\", \"TRUE\")\n",
                "\n",
                "import torch\n",
                "from models.eomt import EoMT\n",
                "from models.vit import ViT\n",
                "\n",
                "try:\n",
                "    from torchinfo import summary\n",
                "except ImportError:\n",
                "    print(\"torchinfo not found. Install it with `pip install torchinfo` for a prettier summary, or we will just use print(model).\")\n",
                "    summary = None"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "36dbb081",
            "metadata": {},
            "source": [
                "## 1. Model Configuration\n",
                "We set up the configuration parameters matching `configs/dinov2/cityscapes/semantic/eomt_base_640.yaml`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "fc1174b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration Parameters\n",
                "img_size = (640, 640)\n",
                "patch_size = 14\n",
                "backbone_name = \"vit_base_patch14_reg4_dinov2\"\n",
                "num_classes = 19  # Cityscapes\n",
                "num_q = 100\n",
                "num_blocks = 3\n",
                "masked_attn_enabled = True"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bf782166",
            "metadata": {},
            "source": [
                "## 2. Model Instantiation\n",
                "First we create the ViT encoder backbone, then wrap it in the EoMT model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "d79a26e7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Initializing ViT Backbone...\n",
                        "Initializing EoMT Model...\n"
                    ]
                }
            ],
            "source": [
                "print(\"Initializing ViT Backbone...\")\n",
                "encoder = ViT(\n",
                "    img_size=img_size,\n",
                "    patch_size=patch_size,\n",
                "    backbone_name=backbone_name,\n",
                "    ckpt_path=None # We don't need weights for visualization\n",
                ")\n",
                "\n",
                "print(\"Initializing EoMT Model...\")\n",
                "model = EoMT(\n",
                "    encoder=encoder,\n",
                "    num_classes=num_classes,\n",
                "    num_q=num_q,\n",
                "    num_blocks=num_blocks,\n",
                "    masked_attn_enabled=masked_attn_enabled\n",
                ")\n",
                "\n",
                "# Move to evaluatoin mode\n",
                "model.eval();"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6d3bc44a",
            "metadata": {},
            "source": [
                "## 3. Architecture Summary\n",
                "Using `torchinfo` if available, otherwise printing the pytorch module."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "342d23a2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "EoMT(\n",
                        "  (encoder): ViT(\n",
                        "    (backbone): VisionTransformer(\n",
                        "      (patch_embed): PatchEmbed(\n",
                        "        (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
                        "        (norm): Identity()\n",
                        "      )\n",
                        "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
                        "      (patch_drop): Identity()\n",
                        "      (norm_pre): Identity()\n",
                        "      (blocks): Sequential(\n",
                        "        (0): Block(\n",
                        "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (attn): Attention(\n",
                        "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "            (q_norm): Identity()\n",
                        "            (k_norm): Identity()\n",
                        "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls1): LayerScale()\n",
                        "          (drop_path1): Identity()\n",
                        "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (mlp): Mlp(\n",
                        "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "            (act): GELU(approximate='none')\n",
                        "            (drop1): Dropout(p=0.0, inplace=False)\n",
                        "            (norm): Identity()\n",
                        "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "            (drop2): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls2): LayerScale()\n",
                        "          (drop_path2): Identity()\n",
                        "        )\n",
                        "        (1): Block(\n",
                        "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (attn): Attention(\n",
                        "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "            (q_norm): Identity()\n",
                        "            (k_norm): Identity()\n",
                        "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls1): LayerScale()\n",
                        "          (drop_path1): Identity()\n",
                        "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (mlp): Mlp(\n",
                        "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "            (act): GELU(approximate='none')\n",
                        "            (drop1): Dropout(p=0.0, inplace=False)\n",
                        "            (norm): Identity()\n",
                        "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "            (drop2): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls2): LayerScale()\n",
                        "          (drop_path2): Identity()\n",
                        "        )\n",
                        "        (2): Block(\n",
                        "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (attn): Attention(\n",
                        "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "            (q_norm): Identity()\n",
                        "            (k_norm): Identity()\n",
                        "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls1): LayerScale()\n",
                        "          (drop_path1): Identity()\n",
                        "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (mlp): Mlp(\n",
                        "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "            (act): GELU(approximate='none')\n",
                        "            (drop1): Dropout(p=0.0, inplace=False)\n",
                        "            (norm): Identity()\n",
                        "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "            (drop2): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls2): LayerScale()\n",
                        "          (drop_path2): Identity()\n",
                        "        )\n",
                        "        (3): Block(\n",
                        "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (attn): Attention(\n",
                        "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "            (q_norm): Identity()\n",
                        "            (k_norm): Identity()\n",
                        "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls1): LayerScale()\n",
                        "          (drop_path1): Identity()\n",
                        "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (mlp): Mlp(\n",
                        "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "            (act): GELU(approximate='none')\n",
                        "            (drop1): Dropout(p=0.0, inplace=False)\n",
                        "            (norm): Identity()\n",
                        "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "            (drop2): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls2): LayerScale()\n",
                        "          (drop_path2): Identity()\n",
                        "        )\n",
                        "        (4): Block(\n",
                        "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (attn): Attention(\n",
                        "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "            (q_norm): Identity()\n",
                        "            (k_norm): Identity()\n",
                        "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls1): LayerScale()\n",
                        "          (drop_path1): Identity()\n",
                        "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (mlp): Mlp(\n",
                        "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "            (act): GELU(approximate='none')\n",
                        "            (drop1): Dropout(p=0.0, inplace=False)\n",
                        "            (norm): Identity()\n",
                        "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "            (drop2): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls2): LayerScale()\n",
                        "          (drop_path2): Identity()\n",
                        "        )\n",
                        "        (5): Block(\n",
                        "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (attn): Attention(\n",
                        "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "            (q_norm): Identity()\n",
                        "            (k_norm): Identity()\n",
                        "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls1): LayerScale()\n",
                        "          (drop_path1): Identity()\n",
                        "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (mlp): Mlp(\n",
                        "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "            (act): GELU(approximate='none')\n",
                        "            (drop1): Dropout(p=0.0, inplace=False)\n",
                        "            (norm): Identity()\n",
                        "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "            (drop2): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls2): LayerScale()\n",
                        "          (drop_path2): Identity()\n",
                        "        )\n",
                        "        (6): Block(\n",
                        "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (attn): Attention(\n",
                        "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "            (q_norm): Identity()\n",
                        "            (k_norm): Identity()\n",
                        "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls1): LayerScale()\n",
                        "          (drop_path1): Identity()\n",
                        "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (mlp): Mlp(\n",
                        "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "            (act): GELU(approximate='none')\n",
                        "            (drop1): Dropout(p=0.0, inplace=False)\n",
                        "            (norm): Identity()\n",
                        "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "            (drop2): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls2): LayerScale()\n",
                        "          (drop_path2): Identity()\n",
                        "        )\n",
                        "        (7): Block(\n",
                        "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (attn): Attention(\n",
                        "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "            (q_norm): Identity()\n",
                        "            (k_norm): Identity()\n",
                        "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls1): LayerScale()\n",
                        "          (drop_path1): Identity()\n",
                        "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (mlp): Mlp(\n",
                        "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "            (act): GELU(approximate='none')\n",
                        "            (drop1): Dropout(p=0.0, inplace=False)\n",
                        "            (norm): Identity()\n",
                        "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "            (drop2): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls2): LayerScale()\n",
                        "          (drop_path2): Identity()\n",
                        "        )\n",
                        "        (8): Block(\n",
                        "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (attn): Attention(\n",
                        "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "            (q_norm): Identity()\n",
                        "            (k_norm): Identity()\n",
                        "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls1): LayerScale()\n",
                        "          (drop_path1): Identity()\n",
                        "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (mlp): Mlp(\n",
                        "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "            (act): GELU(approximate='none')\n",
                        "            (drop1): Dropout(p=0.0, inplace=False)\n",
                        "            (norm): Identity()\n",
                        "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "            (drop2): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls2): LayerScale()\n",
                        "          (drop_path2): Identity()\n",
                        "        )\n",
                        "        (9): Block(\n",
                        "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (attn): Attention(\n",
                        "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "            (q_norm): Identity()\n",
                        "            (k_norm): Identity()\n",
                        "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls1): LayerScale()\n",
                        "          (drop_path1): Identity()\n",
                        "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (mlp): Mlp(\n",
                        "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "            (act): GELU(approximate='none')\n",
                        "            (drop1): Dropout(p=0.0, inplace=False)\n",
                        "            (norm): Identity()\n",
                        "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "            (drop2): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls2): LayerScale()\n",
                        "          (drop_path2): Identity()\n",
                        "        )\n",
                        "        (10): Block(\n",
                        "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (attn): Attention(\n",
                        "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "            (q_norm): Identity()\n",
                        "            (k_norm): Identity()\n",
                        "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls1): LayerScale()\n",
                        "          (drop_path1): Identity()\n",
                        "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (mlp): Mlp(\n",
                        "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "            (act): GELU(approximate='none')\n",
                        "            (drop1): Dropout(p=0.0, inplace=False)\n",
                        "            (norm): Identity()\n",
                        "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "            (drop2): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls2): LayerScale()\n",
                        "          (drop_path2): Identity()\n",
                        "        )\n",
                        "        (11): Block(\n",
                        "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (attn): Attention(\n",
                        "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "            (q_norm): Identity()\n",
                        "            (k_norm): Identity()\n",
                        "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls1): LayerScale()\n",
                        "          (drop_path1): Identity()\n",
                        "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "          (mlp): Mlp(\n",
                        "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "            (act): GELU(approximate='none')\n",
                        "            (drop1): Dropout(p=0.0, inplace=False)\n",
                        "            (norm): Identity()\n",
                        "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "            (drop2): Dropout(p=0.0, inplace=False)\n",
                        "          )\n",
                        "          (ls2): LayerScale()\n",
                        "          (drop_path2): Identity()\n",
                        "        )\n",
                        "      )\n",
                        "      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "      (fc_norm): Identity()\n",
                        "      (head_drop): Dropout(p=0.0, inplace=False)\n",
                        "      (head): Identity()\n",
                        "    )\n",
                        "  )\n",
                        "  (q): Embedding(100, 768)\n",
                        "  (class_head): Linear(in_features=768, out_features=20, bias=True)\n",
                        "  (mask_head): Sequential(\n",
                        "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
                        "    (1): GELU(approximate='none')\n",
                        "    (2): Linear(in_features=768, out_features=768, bias=True)\n",
                        "    (3): GELU(approximate='none')\n",
                        "    (4): Linear(in_features=768, out_features=768, bias=True)\n",
                        "  )\n",
                        "  (upscale): Sequential(\n",
                        "    (0): ScaleBlock(\n",
                        "      (conv1): ConvTranspose2d(768, 768, kernel_size=(2, 2), stride=(2, 2))\n",
                        "      (act): GELU(approximate='none')\n",
                        "      (conv2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
                        "      (norm): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
                        "    )\n",
                        "  )\n",
                        ")\n"
                    ]
                }
            ],
            "source": [
                "if summary:\n",
                "    summary(model, input_size=(1, 3, *img_size), depth=4)\n",
                "else:\n",
                "    print(model)\n",
                "print(model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "5e84afa5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ViT(\n",
                        "  (backbone): VisionTransformer(\n",
                        "    (patch_embed): PatchEmbed(\n",
                        "      (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
                        "      (norm): Identity()\n",
                        "    )\n",
                        "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
                        "    (patch_drop): Identity()\n",
                        "    (norm_pre): Identity()\n",
                        "    (blocks): Sequential(\n",
                        "      (0): Block(\n",
                        "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (attn): Attention(\n",
                        "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "          (q_norm): Identity()\n",
                        "          (k_norm): Identity()\n",
                        "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls1): LayerScale()\n",
                        "        (drop_path1): Identity()\n",
                        "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (mlp): Mlp(\n",
                        "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "          (act): GELU(approximate='none')\n",
                        "          (drop1): Dropout(p=0.0, inplace=False)\n",
                        "          (norm): Identity()\n",
                        "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "          (drop2): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls2): LayerScale()\n",
                        "        (drop_path2): Identity()\n",
                        "      )\n",
                        "      (1): Block(\n",
                        "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (attn): Attention(\n",
                        "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "          (q_norm): Identity()\n",
                        "          (k_norm): Identity()\n",
                        "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls1): LayerScale()\n",
                        "        (drop_path1): Identity()\n",
                        "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (mlp): Mlp(\n",
                        "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "          (act): GELU(approximate='none')\n",
                        "          (drop1): Dropout(p=0.0, inplace=False)\n",
                        "          (norm): Identity()\n",
                        "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "          (drop2): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls2): LayerScale()\n",
                        "        (drop_path2): Identity()\n",
                        "      )\n",
                        "      (2): Block(\n",
                        "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (attn): Attention(\n",
                        "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "          (q_norm): Identity()\n",
                        "          (k_norm): Identity()\n",
                        "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls1): LayerScale()\n",
                        "        (drop_path1): Identity()\n",
                        "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (mlp): Mlp(\n",
                        "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "          (act): GELU(approximate='none')\n",
                        "          (drop1): Dropout(p=0.0, inplace=False)\n",
                        "          (norm): Identity()\n",
                        "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "          (drop2): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls2): LayerScale()\n",
                        "        (drop_path2): Identity()\n",
                        "      )\n",
                        "      (3): Block(\n",
                        "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (attn): Attention(\n",
                        "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "          (q_norm): Identity()\n",
                        "          (k_norm): Identity()\n",
                        "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls1): LayerScale()\n",
                        "        (drop_path1): Identity()\n",
                        "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (mlp): Mlp(\n",
                        "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "          (act): GELU(approximate='none')\n",
                        "          (drop1): Dropout(p=0.0, inplace=False)\n",
                        "          (norm): Identity()\n",
                        "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "          (drop2): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls2): LayerScale()\n",
                        "        (drop_path2): Identity()\n",
                        "      )\n",
                        "      (4): Block(\n",
                        "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (attn): Attention(\n",
                        "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "          (q_norm): Identity()\n",
                        "          (k_norm): Identity()\n",
                        "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls1): LayerScale()\n",
                        "        (drop_path1): Identity()\n",
                        "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (mlp): Mlp(\n",
                        "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "          (act): GELU(approximate='none')\n",
                        "          (drop1): Dropout(p=0.0, inplace=False)\n",
                        "          (norm): Identity()\n",
                        "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "          (drop2): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls2): LayerScale()\n",
                        "        (drop_path2): Identity()\n",
                        "      )\n",
                        "      (5): Block(\n",
                        "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (attn): Attention(\n",
                        "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "          (q_norm): Identity()\n",
                        "          (k_norm): Identity()\n",
                        "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls1): LayerScale()\n",
                        "        (drop_path1): Identity()\n",
                        "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (mlp): Mlp(\n",
                        "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "          (act): GELU(approximate='none')\n",
                        "          (drop1): Dropout(p=0.0, inplace=False)\n",
                        "          (norm): Identity()\n",
                        "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "          (drop2): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls2): LayerScale()\n",
                        "        (drop_path2): Identity()\n",
                        "      )\n",
                        "      (6): Block(\n",
                        "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (attn): Attention(\n",
                        "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "          (q_norm): Identity()\n",
                        "          (k_norm): Identity()\n",
                        "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls1): LayerScale()\n",
                        "        (drop_path1): Identity()\n",
                        "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (mlp): Mlp(\n",
                        "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "          (act): GELU(approximate='none')\n",
                        "          (drop1): Dropout(p=0.0, inplace=False)\n",
                        "          (norm): Identity()\n",
                        "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "          (drop2): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls2): LayerScale()\n",
                        "        (drop_path2): Identity()\n",
                        "      )\n",
                        "      (7): Block(\n",
                        "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (attn): Attention(\n",
                        "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "          (q_norm): Identity()\n",
                        "          (k_norm): Identity()\n",
                        "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls1): LayerScale()\n",
                        "        (drop_path1): Identity()\n",
                        "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (mlp): Mlp(\n",
                        "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "          (act): GELU(approximate='none')\n",
                        "          (drop1): Dropout(p=0.0, inplace=False)\n",
                        "          (norm): Identity()\n",
                        "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "          (drop2): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls2): LayerScale()\n",
                        "        (drop_path2): Identity()\n",
                        "      )\n",
                        "      (8): Block(\n",
                        "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (attn): Attention(\n",
                        "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "          (q_norm): Identity()\n",
                        "          (k_norm): Identity()\n",
                        "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls1): LayerScale()\n",
                        "        (drop_path1): Identity()\n",
                        "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (mlp): Mlp(\n",
                        "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "          (act): GELU(approximate='none')\n",
                        "          (drop1): Dropout(p=0.0, inplace=False)\n",
                        "          (norm): Identity()\n",
                        "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "          (drop2): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls2): LayerScale()\n",
                        "        (drop_path2): Identity()\n",
                        "      )\n",
                        "      (9): Block(\n",
                        "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (attn): Attention(\n",
                        "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "          (q_norm): Identity()\n",
                        "          (k_norm): Identity()\n",
                        "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls1): LayerScale()\n",
                        "        (drop_path1): Identity()\n",
                        "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (mlp): Mlp(\n",
                        "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "          (act): GELU(approximate='none')\n",
                        "          (drop1): Dropout(p=0.0, inplace=False)\n",
                        "          (norm): Identity()\n",
                        "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "          (drop2): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls2): LayerScale()\n",
                        "        (drop_path2): Identity()\n",
                        "      )\n",
                        "      (10): Block(\n",
                        "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (attn): Attention(\n",
                        "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "          (q_norm): Identity()\n",
                        "          (k_norm): Identity()\n",
                        "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls1): LayerScale()\n",
                        "        (drop_path1): Identity()\n",
                        "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (mlp): Mlp(\n",
                        "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "          (act): GELU(approximate='none')\n",
                        "          (drop1): Dropout(p=0.0, inplace=False)\n",
                        "          (norm): Identity()\n",
                        "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "          (drop2): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls2): LayerScale()\n",
                        "        (drop_path2): Identity()\n",
                        "      )\n",
                        "      (11): Block(\n",
                        "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (attn): Attention(\n",
                        "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
                        "          (q_norm): Identity()\n",
                        "          (k_norm): Identity()\n",
                        "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
                        "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls1): LayerScale()\n",
                        "        (drop_path1): Identity()\n",
                        "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "        (mlp): Mlp(\n",
                        "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
                        "          (act): GELU(approximate='none')\n",
                        "          (drop1): Dropout(p=0.0, inplace=False)\n",
                        "          (norm): Identity()\n",
                        "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
                        "          (drop2): Dropout(p=0.0, inplace=False)\n",
                        "        )\n",
                        "        (ls2): LayerScale()\n",
                        "        (drop_path2): Identity()\n",
                        "      )\n",
                        "    )\n",
                        "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
                        "    (fc_norm): Identity()\n",
                        "    (head_drop): Dropout(p=0.0, inplace=False)\n",
                        "    (head): Identity()\n",
                        "  )\n",
                        ")\n"
                    ]
                }
            ],
            "source": [
                "print(encoder)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "58060ecb",
            "metadata": {},
            "source": [
                "## 4. Forward Pass Check\n",
                "Running a dummy input to verify output shapes.\n",
                "\n",
                "Expected outputs:\n",
                "1. `mask_logits_list`: List containing outputs for intermediate blocks + final. Length should be `num_blocks + 1`.\n",
                "2. `class_logits_list`: Same length."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "7736058c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: cuda\n",
                        "Input Shape: torch.Size([1, 3, 640, 640])\n",
                        "Number of outputs (stages): 4\n",
                        "\n",
                        "Final Mask Logits Shape: torch.Size([1, 100, 90, 90])\n",
                        "   Batch: 1\n",
                        "   Queries: 100\n",
                        "   Height: 90\n",
                        "   Width: 90\n",
                        "\n",
                        "Final Class Logits Shape: torch.Size([1, 100, 20])\n",
                        "   Batch: 1\n",
                        "   Queries: 100\n",
                        "   Classes (N+1): 20\n"
                    ]
                }
            ],
            "source": [
                "# Determine device\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# Move model to device\n",
                "model = model.to(device)\n",
                "\n",
                "# Create input on the same device\n",
                "dummy_input = torch.randn(1, 3, *img_size).to(device)\n",
                "\n",
                "with torch.no_grad():\n",
                "    mask_logits_list, class_logits_list = model(dummy_input)\n",
                "\n",
                "print(f\"Input Shape: {dummy_input.shape}\")\n",
                "print(f\"Number of outputs (stages): {len(mask_logits_list)}\")\n",
                "\n",
                "# Check global prediction (last one)\n",
                "final_mask = mask_logits_list[-1]\n",
                "final_class = class_logits_list[-1]\n",
                "\n",
                "print(f\"\\nFinal Mask Logits Shape: {final_mask.shape}\")\n",
                "print(f\"   Batch: {final_mask.shape[0]}\")\n",
                "print(f\"   Queries: {final_mask.shape[1]}\")\n",
                "print(f\"   Height: {final_mask.shape[2]}\")\n",
                "print(f\"   Width: {final_mask.shape[3]}\")\n",
                "\n",
                "print(f\"\\nFinal Class Logits Shape: {final_class.shape}\")\n",
                "print(f\"   Batch: {final_class.shape[0]}\")\n",
                "print(f\"   Queries: {final_class.shape[1]}\")\n",
                "print(f\"   Classes (N+1): {final_class.shape[2]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Raw Timm Model Inspection\n",
                "Checking the layers of the raw `vit_base_patch14_reg4_dinov2` model from `timm` directly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
                        "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
                        "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
                        "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
                    ]
                }
            ],
            "source": [
                "import timm\n",
                "\n",
                "print(\"Downloading and creating raw timm model...\")\n",
                "raw_model = timm.create_model(\"vit_base_patch14_reg4_dinov2\", pretrained=True)\n",
                "print(raw_model)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "eomt",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
